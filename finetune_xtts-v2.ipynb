{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ae7ae-c0a3-4870-a6bd-42805b8e61a4",
   "metadata": {},
   "source": [
    "# Imports & Logging Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b972be61-e87b-45bb-bcad-b71e3729f377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig\n",
    "from TTS.tts.models.xtts import XttsAudioConfig\n",
    "from TTS.utils.manage import ModelManager\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "from trainer.logging.wandb_logger import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cabbd0c-d293-4349-9bf8-5aa69eb02461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "12.6\n",
      "True\n",
      "NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "# Torch info\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "print(torch.version.cuda)           \n",
    "print(torch.cuda.is_available())    \n",
    "print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173d9e5-8a15-4e9b-a7cc-4ff9e6c8ce64",
   "metadata": {},
   "source": [
    "# Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c9d621-ce29-453d-ba9f-867a831db2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get XTTS files\n",
    "CHECKPOINT_PATH = './XTTS-files/'\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# DVAE files\n",
    "DVAE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
    "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
    "\n",
    "# Set the path to the downloaded files\n",
    "DVAE_CHECKPOINT = os.path.join(CHECKPOINT_PATH, os.path.basename(DVAE_LINK))\n",
    "MEL_NORM_FILE = os.path.join(CHECKPOINT_PATH, os.path.basename(MEL_NORM_LINK))\n",
    "\n",
    "# DVAE download if not exists\n",
    "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
    "    print(\" > Downloading DVAE files!\")\n",
    "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_LINK], CHECKPOINT_PATH, progress_bar=True)\n",
    "\n",
    "# XTTS v2.0 checkpoint\n",
    "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
    "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "\n",
    "# Transfer learning parameters\n",
    "TOKENIZER_FILE = os.path.join(CHECKPOINT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json\n",
    "XTTS_CHECKPOINT = os.path.join(CHECKPOINT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth\n",
    "\n",
    "# XTTS v2.0 download if not exists\n",
    "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
    "    print(\" > Downloading XTTS v2.0 files!\")\n",
    "    ModelManager._download_model_files(\n",
    "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINT_PATH, progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e15d7-54f0-45d1-aced-c36f9bdfcf89",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "Make sure your metadata follows LJSpeech format: \\<file\\>|\\<transcription\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711f13db-e5bb-49f2-984e-0d5c3300fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1% to evaluate by listening to tests\n",
    "\n",
    "# Set lang\n",
    "LANGUAGE ='en'\n",
    "\n",
    "# Set to folder name that contains metadata.csv and wavs dir (with the .wav examples)\n",
    "DATASET= \"Sherlock Holmes Stories  Read by Benedict Cumberbatch\"\n",
    "training_dir = f'./datasets/{DATASET}' # change to folder w/ training examples\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    meta_file_train=\"metadata.csv\", # metadata file w/ transcriptions\n",
    "    language=LANGUAGE,\n",
    "    path=training_dir\n",
    ")\n",
    "\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_size=0.02, # Might change\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b169a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio config\n",
    "audio_config = XttsAudioConfig(sample_rate=16000, dvae_sample_rate=16000, output_sample_rate=24000)\n",
    "# audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000) # Docs\n",
    "\n",
    "# Speaker Reference: Match these to the test sentences\n",
    "SPEAKER_TEXT = [\n",
    "    \"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "    \"This cake is great. It's so delicious and moist.\"\n",
    "]\n",
    "\n",
    "SPEAKER_REFERENCE = f\"datasets/{DATASET}/wavs/chunk_0220.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3de044-0dc5-4bc0-8a33-e33fbe9cdf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify model arguments\n",
    "model_args = GPTArgs(\n",
    "    max_conditioning_length=143677, # Audio used for conditioning latents should be less than this\n",
    "    # max_conditioning_length=132300 # Docs has 6 secs\n",
    "    min_conditioning_length=66150, # and more than this\n",
    "    debug_loading_failures=True,\n",
    "    max_wav_length=255995, # Set >= longest audio in dataset\n",
    "    # max_wav_length=255995, # Docs has ~11.6 seconds\n",
    "    max_text_length=66150,\n",
    "    mel_norm_file=MEL_NORM_FILE,\n",
    "    dvae_checkpoint=DVAE_CHECKPOINT,\n",
    "    xtts_checkpoint=XTTS_CHECKPOINT,  \n",
    "    tokenizer_file=TOKENIZER_FILE,\n",
    "    gpt_num_audio_tokens=1026, \n",
    "    gpt_start_audio_token=1024,\n",
    "    gpt_stop_audio_token=1025,\n",
    "    gpt_use_masking_gt_prompt_approach=True,\n",
    "    gpt_use_perceiver_resampler=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf99a01-5134-44c2-ace8-93eafe472a5f",
   "metadata": {},
   "source": [
    "# Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282032f8-aa01-4dab-9d0d-d3daab4d8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = './run/training/'\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.makedirs(OUT_PATH)\n",
    "\n",
    "RUN_NAME = 'Sherlock-Holmes-4-epochs'\n",
    "# RUN_NAME = f\"xttsv2_finetune_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "PROJECT_NAME = 'XTTS-v2 Finetune'\n",
    "DASHBOARD_LOGGER = 'wandb'\n",
    "LOGGER_URI = None\n",
    "\n",
    "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  \n",
    "BATCH_SIZE = 3 # 4 is common\n",
    "GRAD_ACUMM_STEPS = 84 # 252\n",
    "# Note: we recommend that BATCH_SIZE * GRAD_ACUMM_STEPS need to be at least 252 for more efficient training. \n",
    "# You can increase/decrease BATCH_SIZE but then set GRAD_ACUMM_STEPS accordingly.\n",
    "START_WITH_EVAL = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d01cfce-9c86-41a9-a0ee-33502dc92b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTTrainerConfig(\n",
    "    run_eval=True,\n",
    "    epochs = 4, # assuming you want to end training manually w/ keyboard interrupt\n",
    "    output_path=OUT_PATH,\n",
    "    model_args=model_args,\n",
    "    run_name=RUN_NAME,\n",
    "    project_name=PROJECT_NAME,\n",
    "    run_description=\"\"\"\n",
    "        GPT XTTS training\n",
    "        \"\"\",\n",
    "    dashboard_logger=DASHBOARD_LOGGER,\n",
    "    wandb_entity=None,\n",
    "    logger_uri=LOGGER_URI,\n",
    "    audio=audio_config,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    batch_group_size=48,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    num_loader_workers=0, # On Windows, num_loader_workers > 0 can break multiprocessing in PyTorch\n",
    "    eval_split_max_size=256, \n",
    "    print_step=50, \n",
    "    plot_step=100, \n",
    "    log_model_step=1000, \n",
    "    save_step=1000,\n",
    "    save_n_checkpoints=1,\n",
    "    save_checkpoints=True,\n",
    "    print_eval=True,\n",
    "    optimizer=\"AdamW\",\n",
    "    optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
    "    optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
    "    lr=5e-06,  \n",
    "    lr_scheduler=\"MultiStepLR\",\n",
    "    lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
    "    test_sentences=[ \n",
    "        {\n",
    "            \"text\": SPEAKER_TEXT[0],\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE, \n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "        {\n",
    "            \"text\": SPEAKER_TEXT[1],\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "    ],\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dbccc-435c-4e05-bbaa-ecfd4429ed28",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f13184e8-0f97-41a4-a1a4-426754b2e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 20\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: robcaamano (robcaamano-new-jersey-institute-of-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\caama\\Documents\\School\\NJIT\\DS677\\Project\\wandb\\run-20250425_153242-shihfr4u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune/runs/shihfr4u' target=\"_blank\">Sherlock-Holmes-4-epochs</a></strong> to <a href='https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune' target=\"_blank\">https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune/runs/shihfr4u' target=\"_blank\">https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune/runs/shihfr4u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " > Model has 518442047 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/4\u001b[0m\n",
      " --> run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.02065003104507923  (0.02065003104507923)\n",
      "     | > loss_mel_ce: 4.8800153732299805  (4.8800153732299805)\n",
      "     | > loss: 4.900665283203125  (4.900665283203125)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_text_ce: 0.02369523048400879  (0.02369523048400879)\n",
      "     | > loss_mel_ce: 4.812253952026367  (4.812253952026367)\n",
      "     | > loss: 4.835948944091797  (4.835948944091797)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_text_ce: 0.021101634949445724  (0.022398432716727257)\n",
      "     | > loss_mel_ce: 4.779322624206543  (4.795788288116455)\n",
      "     | > loss: 4.800424098968506  (4.818186521530151)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_text_ce: 0.021626941859722137  (0.02214126909772555)\n",
      "     | > loss_mel_ce: 4.4567179679870605  (4.682764848073323)\n",
      "     | > loss: 4.478344917297363  (4.704905986785889)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_text_ce: 0.021944627165794373  (0.022092108614742756)\n",
      "     | > loss_mel_ce: 4.730851650238037  (4.694786548614502)\n",
      "     | > loss: 4.752796173095703  (4.716878533363342)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_text_ce: 0.021313846111297607  (0.021936456114053725)\n",
      "     | > loss_mel_ce: 4.908026218414307  (4.7374344825744625)\n",
      "     | > loss: 4.92933988571167  (4.759370803833008)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_text_ce: 0.02120722085237503  (0.021814916903773945)\n",
      "     | > loss_mel_ce: 4.877439022064209  (4.760768572489421)\n",
      "     | > loss: 4.898646354675293  (4.782583395640056)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.067971666653951 \u001b[0m(+0.0)\n",
      "     | > avg_loss_text_ce: 0.021814916903773945 \u001b[0m(+0.0)\n",
      "     | > avg_loss_mel_ce: 4.760768572489421 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 4.782583395640056 \u001b[0m(+0.0)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/4\u001b[0m\n",
      " --> run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2025-04-25 15:32:48) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:32:48 -- STEP: 0/370 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.022243821993470192  (0.022243821993470192)\n",
      "     | > loss_mel_ce: 5.101950168609619  (5.101950168609619)\n",
      "     | > loss: 0.06100231409072876  (0.06100231409072876)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1675  (0.16753864288330078)\n",
      "     | > loader_time: 0.0578  (0.05779123306274414)\n",
      "\n",
      "wandb: Adding directory to artifact (.\\run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000)... Done. 0.0s\n",
      "Error loading ./datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\wavs\\﻿chunk_0000.wav (<class 'soundfile.LibsndfileError'>, LibsndfileError(2, \"Error opening './datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\\\\\\\wavs\\\\\\\\\\\\ufeffchunk_0000.wav': \"), <traceback object at 0x0000023B853079C0>)\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:32:59 -- STEP: 50/370 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss_text_ce: 0.021904677152633667  (0.023353138603270054)\n",
      "     | > loss_mel_ce: 4.993193626403809  (4.857127528190612)\n",
      "     | > loss: 0.05970355123281479  (0.05810096099972725)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1005  (0.09678604125976563)\n",
      "     | > loader_time: 0.0688  (0.06376024246215821)\n",
      "\n",
      "Error loading ./datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\wavs\\chunk_1125.wav (<class 'soundfile.LibsndfileError'>, LibsndfileError(2, \"Error opening './datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\\\\\\\wavs\\\\\\\\chunk_1125.wav': \"), <traceback object at 0x0000023CE4641940>)\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:33:10 -- STEP: 100/370 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss_text_ce: 0.02186979539692402  (0.023663721550256013)\n",
      "     | > loss_mel_ce: 5.097776889801025  (4.844553368091585)\n",
      "     | > loss: 0.06094817444682121  (0.057954966314136984)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.0988  (0.09716928482055665)\n",
      "     | > loader_time: 0.0654  (0.06155185222625729)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:33:27 -- STEP: 150/370 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss_text_ce: 0.026617947965860367  (0.023607976113756497)\n",
      "     | > loss_mel_ce: 4.41134786605835  (4.817071544329327)\n",
      "     | > loss: 0.05283292755484581  (0.0576271382222573)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1652  (0.14478699684143068)\n",
      "     | > loader_time: 0.0506  (0.06122230370839434)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:33:45 -- STEP: 200/370 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss_text_ce: 0.021193677559494972  (0.023648314159363498)\n",
      "     | > loss_mel_ce: 5.093362331390381  (4.778296085596083)\n",
      "     | > loss: 0.060887571424245834  (0.05716600583866239)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2442  (0.16837600588798524)\n",
      "     | > loader_time: 0.0518  (0.06046860575675963)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:34:07 -- STEP: 250/370 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss_text_ce: 0.025131884962320328  (0.02353110291808843)\n",
      "     | > loss_mel_ce: 4.591299057006836  (4.744694766044616)\n",
      "     | > loss: 0.05495750904083252  (0.05676459476351738)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.6251  (0.19542680931091308)\n",
      "     | > loader_time: 0.0561  (0.059242734909057605)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:34:34 -- STEP: 300/370 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss_text_ce: 0.02108737640082836  (0.023446186544994516)\n",
      "     | > loss_mel_ce: 4.58429479598999  (4.713037026723225)\n",
      "     | > loss: 0.054825976490974426  (0.05638670595983664)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.309  (0.2220542351404825)\n",
      "     | > loader_time: 0.064  (0.05858627716700235)\n",
      "\n",
      "Error loading ./datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\wavs\\chunk_1126.wav (<class 'soundfile.LibsndfileError'>, LibsndfileError(2, \"Error opening './datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\\\\\\\wavs\\\\\\\\chunk_1126.wav': \"), <traceback object at 0x0000023CE4691100>)\n",
      "Error loading ./datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\wavs\\chunk_1127.wav (<class 'soundfile.LibsndfileError'>, LibsndfileError(2, \"Error opening './datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\\\\\\\wavs\\\\\\\\chunk_1127.wav': \"), <traceback object at 0x0000023CE4692380>)\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:35:03 -- STEP: 350/370 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss_text_ce: 0.02510540746152401  (0.02342749032058886)\n",
      "     | > loss_mel_ce: 4.507370948791504  (4.689700372559684)\n",
      "     | > loss: 0.05395805463194847  (0.05610866606235504)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2919  (0.2571346480505805)\n",
      "     | > loader_time: 0.0504  (0.05942114693777901)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.020510518923401833  (0.020510518923401833)\n",
      "     | > loss_mel_ce: 4.415520668029785  (4.415520668029785)\n",
      "     | > loss: 4.436031341552734  (4.436031341552734)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_text_ce: 0.023326100781559944  (0.023326100781559944)\n",
      "     | > loss_mel_ce: 4.377212047576904  (4.377212047576904)\n",
      "     | > loss: 4.400537967681885  (4.400537967681885)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_text_ce: 0.020727654919028282  (0.022026877850294113)\n",
      "     | > loss_mel_ce: 4.428081035614014  (4.402646541595459)\n",
      "     | > loss: 4.448808670043945  (4.424673318862915)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_text_ce: 0.02135774865746498  (0.021803834786017735)\n",
      "     | > loss_mel_ce: 4.123703479766846  (4.309665520985921)\n",
      "     | > loss: 4.145061016082764  (4.331469217936198)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_text_ce: 0.021579544991254807  (0.021747762337327003)\n",
      "     | > loss_mel_ce: 4.3558030128479  (4.321199893951416)\n",
      "     | > loss: 4.377382755279541  (4.342947602272034)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_text_ce: 0.02108408324420452  (0.021615026518702507)\n",
      "     | > loss_mel_ce: 4.472179412841797  (4.351395797729492)\n",
      "     | > loss: 4.4932637214660645  (4.37301082611084)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_text_ce: 0.021006152033805847  (0.021513547437886398)\n",
      "     | > loss_mel_ce: 4.452820301055908  (4.3682998816172285)\n",
      "     | > loss: 4.4738264083862305  (4.389813423156738)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.053555051485697426 \u001b[0m(-0.014416615168253578)\n",
      "     | > avg_loss_text_ce:\u001b[92m 0.021513547437886398 \u001b[0m(-0.00030136946588754654)\n",
      "     | > avg_loss_mel_ce:\u001b[92m 4.3682998816172285 \u001b[0m(-0.3924686908721924)\n",
      "     | > avg_loss:\u001b[92m 4.389813423156738 \u001b[0m(-0.39276997248331735)\n",
      "\n",
      " > BEST MODEL : run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\\best_model_370.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/4\u001b[0m\n",
      " --> run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2025-04-25 15:42:32) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:43:16 -- STEP: 30/370 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss_text_ce: 0.026894470676779747  (0.023517033892373244)\n",
      "     | > loss_mel_ce: 4.286426544189453  (4.536235014597575)\n",
      "     | > loss: 0.05134906247258186  (0.05428276335199674)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.1193  (1.2407461086908975)\n",
      "     | > loader_time: 0.061  (0.06580286820729576)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:44:30 -- STEP: 80/370 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss_text_ce: 0.020265309140086174  (0.02332245339639485)\n",
      "     | > loss_mel_ce: 4.587185382843018  (4.519868713617326)\n",
      "     | > loss: 0.05485060065984726  (0.054085609829053284)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.5204  (1.2585058301687237)\n",
      "     | > loader_time: 0.0553  (0.06231707632541659)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:46:05 -- STEP: 130/370 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss_text_ce: 0.021716615185141563  (0.02332435859223971)\n",
      "     | > loss_mel_ce: 4.268326282501221  (4.471728141491231)\n",
      "     | > loss: 0.05107193812727928  (0.0535125306305977)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.4223  (1.340155234703651)\n",
      "     | > loader_time: 0.0591  (0.060052979909456704)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:47:42 -- STEP: 180/370 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss_text_ce: 0.02513260953128338  (0.023263990496181778)\n",
      "     | > loss_mel_ce: 4.409504413604736  (4.435905818144482)\n",
      "     | > loss: 0.05279329791665077  (0.053085355729692515)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.5689  (1.3993377738528785)\n",
      "     | > loader_time: 0.057  (0.059844989246792275)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:48:57 -- STEP: 230/370 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss_text_ce: 0.022106952965259552  (0.02337654821736657)\n",
      "     | > loss_mel_ce: 4.4055585861206055  (4.422587477642555)\n",
      "     | > loss: 0.05271030589938164  (0.05292814399885095)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.3773  (1.382269625041796)\n",
      "     | > loader_time: 0.049  (0.0590797579806784)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:50:10 -- STEP: 280/370 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss_text_ce: 0.022533811628818512  (0.023330741388989346)\n",
      "     | > loss_mel_ce: 4.354491233825684  (4.404422993319374)\n",
      "     | > loss: 0.052107442170381546  (0.05271135488791127)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.3004  (1.3611662575176788)\n",
      "     | > loader_time: 0.0594  (0.05840702312333243)\n",
      "\n",
      "Error loading ./datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\wavs\\chunk_1124.wav (<class 'soundfile.LibsndfileError'>, LibsndfileError(2, \"Error opening './datasets/Sherlock Holmes Stories  Read by Benedict Cumberbatch\\\\\\\\wavs\\\\\\\\chunk_1124.wav': \"), <traceback object at 0x0000023B837E8280>)\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:51:21 -- STEP: 330/370 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss_text_ce: 0.024143030866980553  (0.023325878534127358)\n",
      "     | > loss_mel_ce: 4.420717716217041  (4.398059265541306)\n",
      "     | > loss: 0.05291501060128212  (0.052635538363547035)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.576  (1.3421022516308416)\n",
      "     | > loader_time: 0.0461  (0.05801166621121493)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.020530207082629204  (0.020530207082629204)\n",
      "     | > loss_mel_ce: 4.196456432342529  (4.196456432342529)\n",
      "     | > loss: 4.216986656188965  (4.216986656188965)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_text_ce: 0.02334950864315033  (0.02334950864315033)\n",
      "     | > loss_mel_ce: 4.248964309692383  (4.248964309692383)\n",
      "     | > loss: 4.272313594818115  (4.272313594818115)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_text_ce: 0.02071545645594597  (0.02203248254954815)\n",
      "     | > loss_mel_ce: 4.16118860244751  (4.205076456069946)\n",
      "     | > loss: 4.181903839111328  (4.227108716964722)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_text_ce: 0.021380366757512093  (0.021815110618869465)\n",
      "     | > loss_mel_ce: 3.9948160648345947  (4.134989658991496)\n",
      "     | > loss: 4.016196250915527  (4.15680456161499)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_text_ce: 0.021596085280179977  (0.021760354284197092)\n",
      "     | > loss_mel_ce: 4.192230224609375  (4.149299800395966)\n",
      "     | > loss: 4.2138261795043945  (4.171059966087341)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_text_ce: 0.021052969619631767  (0.021618877351284028)\n",
      "     | > loss_mel_ce: 4.164346218109131  (4.152309083938599)\n",
      "     | > loss: 4.185399055480957  (4.1739277839660645)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_text_ce: 0.021088141947984695  (0.02153042145073414)\n",
      "     | > loss_mel_ce: 4.265478134155273  (4.171170592308044)\n",
      "     | > loss: 4.286566257476807  (4.1927008628845215)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.05186867713928223 \u001b[0m(-0.0016863743464151995)\n",
      "     | > avg_loss_text_ce:\u001b[91m 0.02153042145073414 \u001b[0m(+1.687401284774029e-05)\n",
      "     | > avg_loss_mel_ce:\u001b[92m 4.171170592308044 \u001b[0m(-0.19712928930918405)\n",
      "     | > avg_loss:\u001b[92m 4.1927008628845215 \u001b[0m(-0.1971125602722168)\n",
      "\n",
      " > BEST MODEL : run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\\best_model_740.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/4\u001b[0m\n",
      " --> run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2025-04-25 15:52:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:52:29 -- STEP: 10/370 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss_text_ce: 0.02256510965526104  (0.02245704475790262)\n",
      "     | > loss_mel_ce: 3.9391355514526367  (4.1820824384689335)\n",
      "     | > loss: 0.04716310277581215  (0.050054042413830754)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1613  (0.1505518674850464)\n",
      "     | > loader_time: 0.0747  (0.05655891895294189)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:53:30 -- STEP: 60/370 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss_text_ce: 0.021704507991671562  (0.022918821933368843)\n",
      "     | > loss_mel_ce: 4.311100959777832  (4.246652718385058)\n",
      "     | > loss: 0.05158102139830589  (0.05082823392003775)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.5485  (0.8912937839825948)\n",
      "     | > loader_time: 0.0551  (0.053878994782765706)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:54:47 -- STEP: 110/370 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss_text_ce: 0.022951900959014893  (0.023229306225072254)\n",
      "     | > loss_mel_ce: 4.11834192276001  (4.219553578983653)\n",
      "     | > loss: 0.04930112138390541  (0.05050932128321042)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.3475  (1.0796060041947795)\n",
      "     | > loader_time: 0.063  (0.053417420387268065)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:55:55 -- STEP: 160/370 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss_text_ce: 0.02229423075914383  (0.023314451915211983)\n",
      "     | > loss_mel_ce: 4.472131252288818  (4.221501983702183)\n",
      "     | > loss: 0.0535050630569458  (0.05053353006951512)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.9858  (1.086505420506)\n",
      "     | > loader_time: 0.0555  (0.05371505171060562)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:57:02 -- STEP: 210/370 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss_text_ce: 0.02548314817249775  (0.023285789610374547)\n",
      "     | > loss_mel_ce: 4.170363903045654  (4.220885909171331)\n",
      "     | > loss: 0.04995056241750717  (0.050525854581168726)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.4506  (1.0816274086634325)\n",
      "     | > loader_time: 0.048  (0.05362717083522252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 15:58:12 -- STEP: 260/370 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss_text_ce: 0.021656055003404617  (0.02331822299613403)\n",
      "     | > loss_mel_ce: 3.416581153869629  (4.2028915139345004)\n",
      "     | > loss: 0.040931396186351776  (0.05031202164693521)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.1874  (1.0757349289380598)\n",
      "     | > loader_time: 0.0471  (0.053684693116408125)\n",
      "\n",
      "\n",
      " > CHECKPOINT : run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\\checkpoint_1000.pth\n",
      "wandb: Adding directory to artifact (.\\run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000)... Done. 160.5s\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 16:02:31 -- STEP: 310/370 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss_text_ce: 0.025072695687413216  (0.023259641506498858)\n",
      "     | > loss_mel_ce: 3.594897985458374  (4.195622468763782)\n",
      "     | > loss: 0.04309489205479622  (0.05022478803030908)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.9598  (1.086009762364049)\n",
      "     | > loader_time: 0.538  (0.10171982780579597)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-04-25 16:04:17 -- STEP: 360/370 -- GLOBAL_STEP: 1100\u001b[0m\n",
      "     | > loss_text_ce: 0.022880369797348976  (0.023263607417336758)\n",
      "     | > loss_mel_ce: 3.9031474590301514  (4.1846900072362665)\n",
      "     | > loss: 0.04673842713236809  (0.0500946868521472)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 1.1608  (1.0995061655839287)\n",
      "     | > loader_time: 0.2102  (0.15172150201267667)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.020514389500021935  (0.020514389500021935)\n",
      "     | > loss_mel_ce: 4.072485446929932  (4.072485446929932)\n",
      "     | > loss: 4.0929999351501465  (4.0929999351501465)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_text_ce: 0.023186031728982925  (0.023186031728982925)\n",
      "     | > loss_mel_ce: 4.185298919677734  (4.185298919677734)\n",
      "     | > loss: 4.208485126495361  (4.208485126495361)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_text_ce: 0.020590269938111305  (0.021888150833547115)\n",
      "     | > loss_mel_ce: 4.081467628479004  (4.133383274078369)\n",
      "     | > loss: 4.102057933807373  (4.155271530151367)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_text_ce: 0.021304158493876457  (0.021693486720323563)\n",
      "     | > loss_mel_ce: 3.9282989501953125  (4.065021832784017)\n",
      "     | > loss: 3.9496030807495117  (4.086715380350749)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_text_ce: 0.02148907072842121  (0.021642382722347975)\n",
      "     | > loss_mel_ce: 4.039842128753662  (4.058726906776428)\n",
      "     | > loss: 4.061331272125244  (4.080369353294373)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_text_ce: 0.02094193734228611  (0.021502293646335602)\n",
      "     | > loss_mel_ce: 4.047915458679199  (4.056564617156982)\n",
      "     | > loss: 4.068857192993164  (4.0780669212341305)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_text_ce: 0.021082067862153053  (0.02143225601563851)\n",
      "     | > loss_mel_ce: 4.153977870941162  (4.072800159454346)\n",
      "     | > loss: 4.175059795379639  (4.094232400258382)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.17308974266052246 \u001b[0m(+0.12122106552124023)\n",
      "     | > avg_loss_text_ce:\u001b[92m 0.02143225601563851 \u001b[0m(-9.816543509562695e-05)\n",
      "     | > avg_loss_mel_ce:\u001b[92m 4.072800159454346 \u001b[0m(-0.09837043285369873)\n",
      "     | > avg_loss:\u001b[92m 4.094232400258382 \u001b[0m(-0.09846846262613962)\n",
      "\n",
      " > BEST MODEL : run\\training\\Sherlock-Holmes-4-epochs-April-25-2025_03+32PM-0000000\\best_model_1110.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>EvalStats/avg_loader_time</td><td>█▂▁</td></tr><tr><td>EvalStats/avg_loss</td><td>█▃▁</td></tr><tr><td>EvalStats/avg_loss_mel_ce</td><td>█▃▁</td></tr><tr><td>EvalStats/avg_loss_text_ce</td><td>█▁▁</td></tr><tr><td>TrainEpochStats/avg_grad_norm</td><td>▁▁</td></tr><tr><td>TrainEpochStats/avg_loader_time</td><td>█▁</td></tr><tr><td>TrainEpochStats/avg_loss</td><td>█▁</td></tr><tr><td>TrainEpochStats/avg_loss_mel_ce</td><td>█▁</td></tr><tr><td>TrainEpochStats/avg_loss_text_ce</td><td>█▁</td></tr><tr><td>TrainEpochStats/avg_step_time</td><td>▁█</td></tr><tr><td>TrainEpochStats/epoch_time</td><td>▁█</td></tr><tr><td>TrainIterStats/current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>TrainIterStats/loader_time</td><td>▁▂▁▂▂▂▁▁▁▁▁█</td></tr><tr><td>TrainIterStats/loss</td><td>███▆▅▅▅▅▅▅▁▃</td></tr><tr><td>TrainIterStats/loss_mel_ce</td><td>███▆▅▅▅▅▅▅▁▃</td></tr><tr><td>TrainIterStats/loss_text_ce</td><td>▂▂▁▁█▂▂▅▂▂▂▃</td></tr><tr><td>TrainIterStats/step_time</td><td>▁▁▂▂▆▇▂██▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>EvalStats/avg_loader_time</td><td>0.05187</td></tr><tr><td>EvalStats/avg_loss</td><td>4.1927</td></tr><tr><td>EvalStats/avg_loss_mel_ce</td><td>4.17117</td></tr><tr><td>EvalStats/avg_loss_text_ce</td><td>0.02153</td></tr><tr><td>TrainEpochStats/avg_grad_norm</td><td>0</td></tr><tr><td>TrainEpochStats/avg_loader_time</td><td>0.05743</td></tr><tr><td>TrainEpochStats/avg_loss</td><td>0.05243</td></tr><tr><td>TrainEpochStats/avg_loss_mel_ce</td><td>4.38085</td></tr><tr><td>TrainEpochStats/avg_loss_text_ce</td><td>0.02336</td></tr><tr><td>TrainEpochStats/avg_step_time</td><td>1.3192</td></tr><tr><td>TrainEpochStats/epoch_time</td><td>579.94839</td></tr><tr><td>TrainIterStats/current_lr</td><td>1e-05</td></tr><tr><td>TrainIterStats/loader_time</td><td>0.2102</td></tr><tr><td>TrainIterStats/loss</td><td>0.04674</td></tr><tr><td>TrainIterStats/loss_mel_ce</td><td>3.90315</td></tr><tr><td>TrainIterStats/loss_text_ce</td><td>0.02288</td></tr><tr><td>TrainIterStats/step_time</td><td>1.1608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sherlock-Holmes-4-epochs</strong> at: <a href='https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune/runs/shihfr4u' target=\"_blank\">https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune/runs/shihfr4u</a><br> View project at: <a href='https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune' target=\"_blank\">https://wandb.ai/robcaamano-new-jersey-institute-of-technology/XTTS-v2%20Finetune</a><br>Synced 5 W&B file(s), 6 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250425_153242-shihfr4u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model init\n",
    "model = GPTTrainer.init_from_config(config)\n",
    "\n",
    "# Model training\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(\n",
    "        restore_path=None, # Change to model path if resuming\n",
    "        skip_train_epoch=False,\n",
    "        start_with_eval=START_WITH_EVAL,\n",
    "        grad_accum_steps=GRAD_ACUMM_STEPS,\n",
    "    ),\n",
    "    config,\n",
    "    output_path=OUT_PATH,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")\n",
    "\n",
    "# Manual interupts will set model to save at given checkpoint\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1aae6-874f-4be5-9a15-6ae13596a0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
